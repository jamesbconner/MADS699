{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4ca64f942f1f455d9a058d4dabe4975a",
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": []
   },
   "source": [
    "# Regression - ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7f2192c30a5f4cc6b597b346f0e3a253",
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0f299d3483114530ad8e368842c371dd",
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Standard Libraries\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import Visualization Libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import shap\n",
    "\n",
    "# Import custom functions\n",
    "import env_functions as ef\n",
    "import s3_functions as sf\n",
    "import common_functions as cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modeling Libraries\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "import neptune\n",
    "\n",
    "# ElasticNet\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the environment and get appropriate vars\n",
    "deepnote, env_vars = ef.load_env_vars()\n",
    "\n",
    "# Iterate through the vars and set them as global vars\n",
    "for var_name, var in env_vars.items():\n",
    "    globals()[var_name] = var\n",
    "\n",
    "# If not in the DeepNote environment, create a dict for aws creds\n",
    "#   that were located in the environment file.  This will be passed\n",
    "#   to all aws s3 functions.\n",
    "if not deepnote:\n",
    "    aws_env_vars = {\n",
    "        'access_key_id': aws_access_key_id,\n",
    "        'secret_access_key': aws_secret_access_key,\n",
    "        'bucket_name': s3_bucket_name\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Configs\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "# Ignore Warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', category=FutureWarning)\n",
    "warnings.simplefilter('ignore', category=UserWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# MapBox Token for Plotly Maps\n",
    "px.set_mapbox_access_token(os.environ.get(\"MAPBOX_TOKEN\"))\n",
    "\n",
    "# Scikit Learn Configs\n",
    "set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    \"\"\"\n",
    "    This is the ElasticNet hyperparam objective function\n",
    "    Hyperparams are passed into this function, which are then used in the model object\n",
    "    The model object is then used in the cross_val_scores function \n",
    "    This results in a list of MAE scores, which are then returned as \n",
    "      the loss and std vars to the trials object\n",
    "\n",
    "    NOTE: Lasso is L1 and Ridge is L2\n",
    "    DO NOT MAKE ALPHA = 0 WHEN USING LASSO\n",
    "    \"\"\"\n",
    "    space['alpha'] = float(space['alpha'])\n",
    "    space['l1_ratio'] = float(space['l1_ratio'])\n",
    "\n",
    "    model = ElasticNet(\n",
    "                alpha=space['alpha'],\n",
    "                l1_ratio=space['l1_ratio'],\n",
    "                fit_intercept=True, # If False, data is assumed to already be centered\n",
    "                precompute=False, # For sparse matrices, set False\n",
    "                max_iter=1000, # Default is 1000\n",
    "                copy_X=True, # Copies the input data, else could be overwritten!\n",
    "                tol=1e-4, # A threshold for optimization\n",
    "                warm_start=False, # When True, Use previous solution as the fit\n",
    "                positive=False, # When True, forces coefficients to be positive\n",
    "                random_state = 42,\n",
    "                selection='cyclic' # 'cyclic' or 'random' -- random could be faster but cyclic is methodical\n",
    "    )\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mae_scores = -cross_val_score(model, X_train_trans, y_train_trans, cv=kf, scoring='neg_mean_absolute_error')\n",
    "    mean_mae = mae_scores.mean()\n",
    "    std_mae = mae_scores.std()\n",
    "\n",
    "    # Emit model specific params and metrics to Neptune\n",
    "    run['parameters/alpha'].log(space['alpha'])\n",
    "    run['parameters/l1_ratio'].log(space['l1_ratio'])\n",
    "    \n",
    "    # Emit standard params and metrics to Neptune\n",
    "    run['parameters/all_parameters'].log(str(space))\n",
    "    run['metrics/mae_scores'].log(str(mae_scores.tolist()))\n",
    "    run[\"metrics/mean_mae\"].log(mean_mae)\n",
    "    run[\"metrics/std_mae\"].log(std_mae)\n",
    "\n",
    "    return {'loss': mean_mae, 'status': STATUS_OK, 'std': std_mae}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Hyperparameter space\n",
    "space = {\n",
    "    'alpha': hp.loguniform('alpha', np.log(1e-1), np.log(1e3)),\n",
    "    'l1_ratio': hp.uniform('l1_ratio', 0, 1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caribbean Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trans, X_val_trans, X_holdout_trans, y_train_trans, y_val_trans, y_holdout_trans = cf.import_data(location_name='CARB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Neptune instance\n",
    "run = neptune.init_run(\n",
    "    name=\"ElasticNet Reg Caribbean\",\n",
    "    tags=[\"ElasticNet\", \"regression\", \"hyperopt\", \"RMSE\", \"Caribbean\", \"CARB\"],\n",
    "    description=\"Elastic Hyperopt with RMSE on Caribbean\"\n",
    ")\n",
    "\n",
    "# Create the Trials object\n",
    "CARB_trials = Trials()\n",
    "\n",
    "# Create the fmin object\n",
    "CARB_best_hyperparams = fmin(fn = objective,\n",
    "                            space = space,\n",
    "                            algo = tpe.suggest,\n",
    "                            max_evals = 1000,\n",
    "                            trials = CARB_trials,\n",
    "                            show_progressbar=True,\n",
    "                            early_stop_fn=no_progress_loss(100))\n",
    "\n",
    "# Stop Neptune instance\n",
    "run.stop()\n",
    "\n",
    "CARB_best_trial = CARB_trials.best_trial\n",
    "CARB_best_hps = CARB_best_hyperparams.copy()\n",
    "\n",
    "CARB_best_hps['alpha'] = float(CARB_best_hps['alpha'])\n",
    "CARB_best_hps['l1_ratio'] = float(CARB_best_hps['l1_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the Hyperparameter Search Validation MAE Scores and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the best trial from the search? Report the MAE & StdDev\n",
    "print(f\"Best Mean Absolute Error: {CARB_trials.best_trial['result']['loss']:.4f}\")\n",
    "print(f\"Best Standard Error: {CARB_trials.best_trial['result']['std']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the best hyperparameters\n",
    "CARB_best_hps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recreate the model and get new MAE and Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the model with the best hyperparameters\n",
    "CARB_model = cf.model_score(hps=CARB_best_hps, model_type='enet', holdout=True, val=True, Xtt=X_train_trans, ytt=y_train_trans, Xvt=X_val_trans, yvt=y_val_trans, Xht=X_holdout_trans, yht=y_holdout_trans)\n",
    "\n",
    "# Plot the feature importance\n",
    "cf.plot_feat_importance(CARB_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# First run through the feature ablation process\n",
    "# This will determine which features can potentially be removed\n",
    "CARB_feature_ablation_df, CARB_baseline_mae_val, CARB_baseline_mae_train = cf.feat_ablation(\n",
    "    model=CARB_model, hps=CARB_best_hps, model_type='enet',\n",
    "    Xtt=X_train_trans, ytt=y_train_trans, \n",
    "    Xvt=X_val_trans, yvt=y_val_trans, \n",
    "    Xht=X_holdout_trans, yht=y_holdout_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the feature ablation dataframe, sorted by the change in MAE to Validation data\n",
    "CARB_feature_ablation_df.sort_values('Val_MAE_Change', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "CARB_feat_ablation_len = len(CARB_feature_ablation_df[CARB_feature_ablation_df['Val_MAE'] <= CARB_baseline_mae_val].sort_values('Val_MAE_Change', ascending=False)['Removed_Feature'])\n",
    "\n",
    "if CARB_feat_ablation_len > 0:\n",
    "    # Generate the top features to use in feature ablation combinations\n",
    "    CARB_abl_list_to_combo = CARB_feature_ablation_df[CARB_feature_ablation_df['Val_MAE'] <= CARB_baseline_mae_val].sort_values('Val_MAE_Change', ascending=False)['Removed_Feature'].head(5).to_list()\n",
    "\n",
    "    # Second run through the feature ablation process\n",
    "    # This time including the top 5 features whose removal decreased the MAE\n",
    "    # These top 5 features will be combined using itertools, and retested \n",
    "    CARB_feature_ablation_df, CARB_baseline_mae_val, CARB_baseline_mae_train = cf.feat_ablation(\n",
    "        model=CARB_model, hps=CARB_best_hps, model_type='enet',\n",
    "        Xtt=X_train_trans, ytt=y_train_trans, \n",
    "        Xvt=X_val_trans, yvt=y_val_trans, \n",
    "        Xht=X_holdout_trans, yht=y_holdout_trans, \n",
    "        abl_list_to_combo=CARB_abl_list_to_combo)\n",
    "\n",
    "    # Show the top 1 feature that decreased the MAE in the second ablation run, which we'll remove.  \n",
    "    # Might be multiple features due to itertools combinations, so we split the string\n",
    "    CARB_drop_cols = CARB_feature_ablation_df[CARB_feature_ablation_df['Val_MAE'] <= CARB_baseline_mae_val].sort_values('Val_MAE_Change', ascending=False)['Removed_Feature'].head(1).values[0].split(', ')\n",
    "\n",
    "    # Create the feature columns list for saving out\n",
    "    CARB_feat_columns = X_train_trans.drop(columns=CARB_drop_cols).columns.to_list()\n",
    "\n",
    "    # Recreate the model with the dropped columns\n",
    "    # It should have a lower MAE score than the original\n",
    "    CARB_experiment_model = cf.model_score(\n",
    "        CARB_best_hps, val=True, model_type='enet',\n",
    "        Xtt=X_train_trans.drop(columns=CARB_drop_cols), ytt=y_train_trans, \n",
    "        Xvt=X_val_trans.drop(columns=CARB_drop_cols), yvt=y_val_trans, \n",
    "        Xht=X_holdout_trans.drop(columns=CARB_drop_cols), yht=y_holdout_trans)\n",
    "\n",
    "    # Plot the feature importance for this model\n",
    "    cf.plot_feat_importance(CARB_experiment_model)\n",
    "\n",
    "else:\n",
    "    CARB_feat_columns = X_train_trans.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output the Model, Trials, Parameters and Feature List to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the model artifacts to disk\n",
    "cf.write_out(model=CARB_model, trials=CARB_trials, params=CARB_best_hps, feat_cols=CARB_feat_columns, model_family='elasticnet_reg', location_name='CARB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Holdout Truth vs Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = y_val_trans.copy(deep=True)\n",
    "CARB_val_pred = CARB_model.predict(X_val_trans)\n",
    "CARB_val_pred = np.clip(CARB_val_pred, 0, 100)\n",
    "eval_df['predictions'] = CARB_val_pred.tolist()\n",
    "eval_df['diff'] = eval_df['y_val'] - eval_df['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.sort_values(by='diff', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(eval_df[eval_df['y_val'] > 5], x='diff', nbins=100, title='Distribution of the diff between prediction and holdout where true value > 5')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_df[(eval_df['diff'].between(-5,5))].sample(10)\n",
    "#eval_df[(eval_df['diff'].between(-5,5)) & (eval_df['y_val'] > 5)].sample(10)\n",
    "eval_df[~(eval_df['diff'].between(-5,5))].sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SHAP Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# CARB_X_val_trans = X_val_trans.copy(deep=True)\n",
    "# CARB_y_val_trans = y_val_trans.copy(deep=True)\n",
    "# explainer = shap.TreeExplainer(CARB_model)\n",
    "# shap_values = explainer(CARB_X_val_trans)\n",
    "# shap_interaction = explainer.shap_interaction_values(CARB_X_val_trans)\n",
    "# sv = explainer.shap_values(CARB_X_val_trans)\n",
    "# shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beeswarm Importance\n",
    "# plt.figure(figsize=(8,6))\n",
    "# plt.title(f\"SHAP Beeswarm Analysis\")\n",
    "# shap.plots.beeswarm(shap_values, max_display=32)\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate Individual Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#investigate = CARB_X_val_trans.index.get_loc(5809)\n",
    "# print(CARB_y_val_trans.iloc[investigate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waterfall on a prediction\n",
    "# plt.figure(figsize=(8,6))\n",
    "# shap.plots.waterfall(shap_values[investigate], max_display=20) # , show=False\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision plot on a prediction\n",
    "# shap.decision_plot(explainer.expected_value, explainer.shap_values(CARB_X_val_trans)[investigate], CARB_X_val_trans, feature_display_range=slice(-1,-51,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# South East Asia and Australia Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trans, X_val_trans, X_holdout_trans, y_train_trans, y_val_trans, y_holdout_trans = cf.import_data(location_name='SEAA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Neptune instance\n",
    "run = neptune.init_run(\n",
    "    name=\"ElasticNet Reg South East Asia and Australia\",\n",
    "    tags=[\"ElasticNet\", \"regression\", \"hyperopt\", \"RMSE\", \"South East Asia and Australia\", \"SEAA\"],\n",
    "    description=\"ElasticNet Hyperopt with RMSE on South East Asia and Australia\"\n",
    ")\n",
    "\n",
    "# Create the Trials object\n",
    "SEAA_trials = Trials()\n",
    "\n",
    "# Create the fmin object\n",
    "SEAA_best_hyperparams = fmin(fn = objective,\n",
    "                            space = space,\n",
    "                            algo = tpe.suggest,\n",
    "                            max_evals = 1000,\n",
    "                            trials = SEAA_trials,\n",
    "                            show_progressbar=True,\n",
    "                            early_stop_fn=no_progress_loss(100))\n",
    "\n",
    "# Stop Neptune instance\n",
    "run.stop()\n",
    "\n",
    "SEAA_best_trial = SEAA_trials.best_trial\n",
    "SEAA_best_hps = SEAA_best_hyperparams.copy()\n",
    "\n",
    "SEAA_best_hps['alpha'] = float(SEAA_best_hps['alpha'])\n",
    "SEAA_best_hps['l1_ratio'] = float(SEAA_best_hps['l1_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the Hyperparameter Search Validation MAE Scores and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the best trial from the search? Report the MAE & StdDev\n",
    "print(f\"Best Mean Absolute Error: {SEAA_trials.best_trial['result']['loss']:.4f}\")\n",
    "print(f\"Best Standard Error: {SEAA_trials.best_trial['result']['std']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the best hyperparameters\n",
    "SEAA_best_hps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recreate the model and get new MAE and Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the model with the best hyperparameters\n",
    "SEAA_model = cf.model_score(hps=SEAA_best_hps, model_type='enet', holdout=True, val=True, Xtt=X_train_trans, ytt=y_train_trans, Xvt=X_val_trans, yvt=y_val_trans, Xht=X_holdout_trans, yht=y_holdout_trans)\n",
    "\n",
    "# Plot the feature importance\n",
    "cf.plot_feat_importance(SEAA_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# First run through the feature ablation process\n",
    "# This will determine which features can potentially be removed\n",
    "SEAA_feature_ablation_df, SEAA_baseline_mae_val, SEAA_baseline_mae_train = cf.feat_ablation(\n",
    "    model=SEAA_model, hps=SEAA_best_hps, model_type='enet',\n",
    "    Xtt=X_train_trans, ytt=y_train_trans, \n",
    "    Xvt=X_val_trans, yvt=y_val_trans, \n",
    "    Xht=X_holdout_trans, yht=y_holdout_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the feature ablation dataframe, sorted by the change in MAE to Validation data\n",
    "SEAA_feature_ablation_df.sort_values('Val_MAE_Change', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "SEAA_feat_ablation_len = len(SEAA_feature_ablation_df[SEAA_feature_ablation_df['Val_MAE'] <= SEAA_baseline_mae_val].sort_values('Val_MAE_Change', ascending=False)['Removed_Feature'])\n",
    "\n",
    "if SEAA_feat_ablation_len > 0:\n",
    "    # Generate the top features to use in feature ablation combinations\n",
    "    SEAA_abl_list_to_combo = SEAA_feature_ablation_df[SEAA_feature_ablation_df['Val_MAE'] <= SEAA_baseline_mae_val].sort_values('Val_MAE_Change', ascending=False)['Removed_Feature'].head(5).to_list()\n",
    "\n",
    "    # Second run through the feature ablation process\n",
    "    # This time including the top 5 features whose removal decreased the MAE\n",
    "    # These top 5 features will be combined using itertools, and retested \n",
    "    SEAA_feature_ablation_df, SEAA_baseline_mae_val, SEAA_baseline_mae_train = cf.feat_ablation(\n",
    "        model=SEAA_model, hps=SEAA_best_hps, model_type='enet',\n",
    "        Xtt=X_train_trans, ytt=y_train_trans, \n",
    "        Xvt=X_val_trans, yvt=y_val_trans, \n",
    "        Xht=X_holdout_trans, yht=y_holdout_trans, \n",
    "        abl_list_to_combo=SEAA_abl_list_to_combo)\n",
    "\n",
    "    # Show the top 1 feature that decreased the MAE in the second ablation run, which we'll remove.  \n",
    "    # Might be multiple features due to itertools combinations, so we split the string\n",
    "    SEAA_drop_cols = SEAA_feature_ablation_df[SEAA_feature_ablation_df['Val_MAE'] <= SEAA_baseline_mae_val].sort_values('Val_MAE_Change', ascending=False)['Removed_Feature'].head(1).values[0].split(', ')\n",
    "\n",
    "    # Create the feature columns list for saving out\n",
    "    SEAA_feat_columns = X_train_trans.drop(columns=SEAA_drop_cols).columns.to_list()\n",
    "\n",
    "    # Recreate the model with the dropped columns\n",
    "    # It should have a lower MAE score than the original\n",
    "    SEAA_experiment_model = cf.model_score(\n",
    "        SEAA_best_hps, val=True, model_type='enet',\n",
    "        Xtt=X_train_trans.drop(columns=SEAA_drop_cols), ytt=y_train_trans, \n",
    "        Xvt=X_val_trans.drop(columns=SEAA_drop_cols), yvt=y_val_trans, \n",
    "        Xht=X_holdout_trans.drop(columns=SEAA_drop_cols), yht=y_holdout_trans)\n",
    "\n",
    "    # Plot the feature importance for this model\n",
    "    cf.plot_feat_importance(SEAA_experiment_model)\n",
    "\n",
    "else:\n",
    "    SEAA_feat_columns = X_train_trans.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output the Model, Trials, Parameters and Feature List to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the model artifacts to disk\n",
    "cf.write_out(model=SEAA_model, trials=SEAA_trials, params=SEAA_best_hps, feat_cols=SEAA_feat_columns, model_family='elasticnet_reg', location_name='SEAA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Holdout Truth vs Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = y_val_trans.copy(deep=True)\n",
    "SEAA_val_pred = SEAA_model.predict(X_val_trans)\n",
    "SEAA_val_pred = np.clip(SEAA_val_pred, 0, 100)\n",
    "eval_df['predictions'] = SEAA_val_pred.tolist()\n",
    "eval_df['diff'] = eval_df['y_val'] - eval_df['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.sort_values(by='diff', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(eval_df[eval_df['y_val'] > 5], x='diff', nbins=100, title='Distribution of the diff between prediction and holdout where true value > 5')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_df[(eval_df['diff'].between(-5,5))].sample(10)\n",
    "#eval_df[(eval_df['diff'].between(-5,5)) & (eval_df['y_val'] > 5)].sample(10)\n",
    "eval_df[~(eval_df['diff'].between(-5,5))].sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df[(eval_df['diff'] > 100) | (eval_df['diff'] < 0)].sort_values(by='diff', ascending=False).head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SHAP Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# SEAA_X_val_trans = X_val_trans.copy(deep=True)\n",
    "# SEAA_y_val_trans = y_val_trans.copy(deep=True)\n",
    "# explainer = shap.TreeExplainer(SEAA_model)\n",
    "# shap_values = explainer(SEAA_X_val_trans)\n",
    "# shap_interaction = explainer.shap_interaction_values(SEAA_X_val_trans)\n",
    "# sv = explainer.shap_values(SEAA_X_val_trans)\n",
    "# shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beeswarm Importance\n",
    "# plt.figure(figsize=(8,6))\n",
    "# plt.title(f\"SHAP Beeswarm Analysis\")\n",
    "# shap.plots.beeswarm(shap_values, max_display=32)\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate Individual Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#investigate = SEAA_X_val_trans.index.get_loc(5809)\n",
    "# print(SEAA_y_val_trans.iloc[investigate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waterfall on a prediction\n",
    "# plt.figure(figsize=(8,6))\n",
    "# shap.plots.waterfall(shap_values[investigate], max_display=20) # , show=False\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision plot on a prediction\n",
    "# shap.decision_plot(explainer.expected_value, explainer.shap_values(SEAA_X_val_trans)[investigate], SEAA_X_val_trans, feature_display_range=slice(-1,-51,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trans, X_val_trans, X_holdout_trans, y_train_trans, y_val_trans, y_holdout_trans = cf.import_data(location_name='GLOB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Neptune instance\n",
    "run = neptune.init_run(\n",
    "    name=\"ElasticNet Reg Global\",\n",
    "    tags=[\"ElasticNet\", \"regression\", \"hyperopt\", \"MAE\", \"Global\", \"GLOB\"],\n",
    "    description=\"ElasticNet Hyperopt with MAE on Global\"\n",
    ")\n",
    "\n",
    "# Create the Trials object\n",
    "GLOB_trials = Trials()\n",
    "\n",
    "# Create the fmin object\n",
    "GLOB_best_hyperparams = fmin(fn = objective,\n",
    "                            space = space,\n",
    "                            algo = tpe.suggest,\n",
    "                            max_evals = 1000,\n",
    "                            trials = GLOB_trials,\n",
    "                            show_progressbar=True,\n",
    "                            early_stop_fn=no_progress_loss(100))\n",
    "\n",
    "# Stop Neptune instance\n",
    "run.stop()\n",
    "\n",
    "GLOB_best_trial = GLOB_trials.best_trial\n",
    "GLOB_best_hps = GLOB_best_hyperparams.copy()\n",
    "\n",
    "GLOB_best_hps['alpha'] = float(GLOB_best_hps['alpha'])\n",
    "GLOB_best_hps['l1_ratio'] = float(GLOB_best_hps['l1_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the Hyperparameter Search Validation MAE Scores and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the best trial from the search? Report the MAE & StdDev\n",
    "print(f\"Best Mean Absolute Error: {GLOB_trials.best_trial['result']['loss']:.4f}\")\n",
    "print(f\"Best Standard Error: {GLOB_trials.best_trial['result']['std']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the best hyperparameters\n",
    "GLOB_best_hps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recreate the model and get new MAE and Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the model with the best hyperparameters\n",
    "GLOB_model = cf.model_score(hps=GLOB_best_hps, model_type='enet', holdout=True, val=True, Xtt=X_train_trans, ytt=y_train_trans, Xvt=X_val_trans, yvt=y_val_trans, Xht=X_holdout_trans, yht=y_holdout_trans)\n",
    "\n",
    "# Plot the feature importance\n",
    "cf.plot_feat_importance(GLOB_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# First run through the feature ablation process\n",
    "# This will determine which features can potentially be removed\n",
    "GLOB_feature_ablation_df, GLOB_baseline_mae_val, GLOB_baseline_mae_train = cf.feat_ablation(\n",
    "    model=GLOB_model, hps=GLOB_best_hps, model_type='enet',\n",
    "    Xtt=X_train_trans, ytt=y_train_trans, \n",
    "    Xvt=X_val_trans, yvt=y_val_trans, \n",
    "    Xht=X_holdout_trans, yht=y_holdout_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the feature ablation dataframe, sorted by the change in MAE to Validation data\n",
    "GLOB_feature_ablation_df.sort_values('Val_MAE_Change', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "GLOB_feat_ablation_len = len(GLOB_feature_ablation_df[GLOB_feature_ablation_df['Val_MAE'] <= GLOB_baseline_mae_val].sort_values('Val_MAE_Change', ascending=False)['Removed_Feature'])\n",
    "\n",
    "if GLOB_feat_ablation_len > 0:\n",
    "    # Generate the top features to use in feature ablation combinations\n",
    "    GLOB_abl_list_to_combo = GLOB_feature_ablation_df[GLOB_feature_ablation_df['Val_MAE'] <= GLOB_baseline_mae_val].sort_values('Val_MAE_Change', ascending=False)['Removed_Feature'].head(5).to_list()\n",
    "\n",
    "    # Second run through the feature ablation process\n",
    "    # This time including the top 5 features whose removal decreased the MAE\n",
    "    # These top 5 features will be combined using itertools, and retested \n",
    "    GLOB_feature_ablation_df, GLOB_baseline_mae_val, GLOB_baseline_mae_train = cf.feat_ablation(\n",
    "        model=GLOB_model, hps=GLOB_best_hps, model_type='enet',\n",
    "        Xtt=X_train_trans, ytt=y_train_trans, \n",
    "        Xvt=X_val_trans, yvt=y_val_trans, \n",
    "        Xht=X_holdout_trans, yht=y_holdout_trans, \n",
    "        abl_list_to_combo=GLOB_abl_list_to_combo)\n",
    "\n",
    "    # Show the top 1 feature that decreased the MAE in the second ablation run, which we'll remove.  \n",
    "    # Might be multiple features due to itertools combinations, so we split the string\n",
    "    GLOB_drop_cols = GLOB_feature_ablation_df[GLOB_feature_ablation_df['Val_MAE'] <= GLOB_baseline_mae_val].sort_values('Val_MAE_Change', ascending=False)['Removed_Feature'].head(1).values[0].split(', ')\n",
    "\n",
    "    # Create the feature columns list for saving out\n",
    "    GLOB_feat_columns = X_train_trans.drop(columns=GLOB_drop_cols).columns.to_list()\n",
    "\n",
    "    # Recreate the model with the dropped columns\n",
    "    # It should have a lower MAE score than the original\n",
    "    GLOB_experiment_model = cf.model_score(\n",
    "        GLOB_best_hps, val=True, model_type='enet',\n",
    "        Xtt=X_train_trans.drop(columns=GLOB_drop_cols), ytt=y_train_trans, \n",
    "        Xvt=X_val_trans.drop(columns=GLOB_drop_cols), yvt=y_val_trans, \n",
    "        Xht=X_holdout_trans.drop(columns=GLOB_drop_cols), yht=y_holdout_trans)\n",
    "\n",
    "    # Plot the feature importance for this model\n",
    "    cf.plot_feat_importance(GLOB_experiment_model)\n",
    "\n",
    "else:\n",
    "    GLOB_feat_columns = X_train_trans.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output the Model, Trials, Parameters and Feature List to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the model artifacts to disk\n",
    "cf.write_out(model=GLOB_model, trials=GLOB_trials, params=GLOB_best_hps, feat_cols=GLOB_feat_columns, model_family='elasticnet_reg', location_name='GLOB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Holdout Truth vs Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = y_val_trans.copy(deep=True)\n",
    "GLOB_val_pred = GLOB_model.predict(X_val_trans)\n",
    "GLOB_val_pred = np.clip(GLOB_val_pred, 0, 100)\n",
    "eval_df['predictions'] = GLOB_val_pred.tolist()\n",
    "eval_df['diff'] = eval_df['y_val'] - eval_df['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.sort_values(by='diff', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(eval_df[eval_df['y_val'] > 5], x='diff', nbins=100, title='Distribution of the diff between prediction and holdout where true value > 5')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_df[(eval_df['diff'].between(-5,5))].sample(10)\n",
    "#eval_df[(eval_df['diff'].between(-5,5)) & (eval_df['y_val'] > 5)].sample(10)\n",
    "eval_df[~(eval_df['diff'].between(-5,5))].sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SHAP Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# GLOB_X_val_trans = X_val_trans.copy(deep=True)\n",
    "# GLOB_y_val_trans = y_val_trans.copy(deep=True)\n",
    "# explainer = shap.TreeExplainer(GLOB_model)\n",
    "# shap_values = explainer(GLOB_X_val_trans)\n",
    "# shap_interaction = explainer.shap_interaction_values(GLOB_X_val_trans)\n",
    "# sv = explainer.shap_values(GLOB_X_val_trans)\n",
    "# shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beeswarm Importance\n",
    "# plt.figure(figsize=(8,6))\n",
    "# plt.title(f\"SHAP Beeswarm Analysis\")\n",
    "# shap.plots.beeswarm(shap_values, max_display=32)\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate Individual Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#investigate = GLOB_X_val_trans.index.get_loc(5809)\n",
    "# print(GLOB_y_val_trans.iloc[investigate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waterfall on a prediction\n",
    "# plt.figure(figsize=(8,6))\n",
    "# shap.plots.waterfall(shap_values[investigate], max_display=20) # , show=False\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision plot on a prediction\n",
    "# shap.decision_plot(explainer.expected_value, explainer.shap_values(GLOB_X_val_trans)[investigate], GLOB_X_val_trans, feature_display_range=slice(-1,-51,-1))"
   ]
  }
 ],
 "metadata": {
  "deepnote_app_layout": "powerful-article",
  "deepnote_app_reactivity_enabled": true,
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "43cca1a49cfb41ce98c0681f44244d1a",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
