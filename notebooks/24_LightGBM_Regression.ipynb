{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "358cdf4319524626906e6c4f1b2b627f",
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": []
   },
   "source": [
    "# Regression - LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9fac7231c2da4ada8d06aa53992621cd",
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1d0f8cb79b7b4f4d8eae88bd8ba166a5",
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Standard Libraries\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import Visualization Libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import shap\n",
    "\n",
    "# Import custom functions\n",
    "import env_functions as ef\n",
    "import s3_functions as sf\n",
    "import common_functions as cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modeling Libraries\n",
    "import lightgbm as lgb\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "import neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the environment and get appropriate vars\n",
    "deepnote, env_vars = ef.load_env_vars()\n",
    "\n",
    "# Iterate through the vars and set them as global vars\n",
    "for var_name, var in env_vars.items():\n",
    "    globals()[var_name] = var\n",
    "\n",
    "# If not in the DeepNote environment, create a dict for aws creds\n",
    "#   that were located in the environment file.  This will be passed\n",
    "#   to all aws s3 functions.\n",
    "if not deepnote:\n",
    "    aws_env_vars = {\n",
    "        'access_key_id': aws_access_key_id,\n",
    "        'secret_access_key': aws_secret_access_key,\n",
    "        'bucket_name': s3_bucket_name\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Configs\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "# Ignore Warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', category=FutureWarning)\n",
    "warnings.simplefilter('ignore', category=UserWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# MapBox Token for Plotly Maps\n",
    "px.set_mapbox_access_token(os.environ.get(\"MAPBOX_TOKEN\"))\n",
    "\n",
    "# Scikit Learn Configs\n",
    "set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    \"\"\"\n",
    "    This is the LightGBM hyperparam objective function\n",
    "    Hyperparams are passed into this function, which are then used in the model object\n",
    "    The model object is then used in the cross_val_scores function \n",
    "    This results in a list of MAE scores, which are then returned as \n",
    "      the loss and std vars to the trials object\n",
    "    \"\"\"\n",
    "    space['num_leaves'] = int(space['num_leaves'])\n",
    "    space['n_estimators'] = int(space['n_estimators'])\n",
    "    space['min_child_samples'] = int(space['min_child_samples'])\n",
    "    space['subsample_freq'] = int(space['subsample_freq'])\n",
    "\n",
    "    model=lgb.LGBMRegressor(\n",
    "                    num_leaves=space['num_leaves'],\n",
    "                    learning_rate=space['learning_rate'],\n",
    "                    n_estimators=space['n_estimators'],\n",
    "                    min_split_gain=space['min_split_gain'],\n",
    "                    min_child_weight=space['min_child_weight'],\n",
    "                    min_child_samples=space['min_child_samples'],\n",
    "                    subsample=space['subsample'],\n",
    "                    subsample_freq=space['subsample_freq'],\n",
    "                    colsample_bytree=space['colsample_bytree'],\n",
    "                    reg_alpha=space['reg_alpha'],\n",
    "                    reg_lambda=space['reg_lambda'],\n",
    "                    boosting_type='dart',\n",
    "                    n_jobs = -1,\n",
    "                    verbose = -1,\n",
    "                    random_state = 42\n",
    "                    )\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mae_scores = -cross_val_score(model, X_train_trans, y_train_trans, cv=kf, scoring='neg_mean_absolute_error')\n",
    "    mean_mae = mae_scores.mean()\n",
    "    std_mae = mae_scores.std()\n",
    "\n",
    "    # Emit model specific params and metrics to Neptune\n",
    "    run['parameters/num_leaves'].log(space['num_leaves'])\n",
    "    run['parameters/learning_rate'].log(space['learning_rate'])\n",
    "    run['parameters/n_estimators'].log(space['n_estimators'])\n",
    "    run['parameters/min_split_gain'].log(space['min_split_gain'])\n",
    "    run['parameters/min_child_weight'].log(space['min_child_weight'])\n",
    "    run['parameters/min_child_samples'].log(space['min_child_samples'])\n",
    "    run['parameters/subsample'].log(space['subsample'])\n",
    "    run['parameters/subsample_freq'].log(space['subsample_freq'])\n",
    "    run['parameters/colsample_bytree'].log(space['colsample_bytree'])\n",
    "    run['parameters/reg_alpha'].log(space['reg_alpha'])\n",
    "    run['parameters/reg_lambda'].log(space['reg_lambda'])\n",
    "    \n",
    "    # Emit standard params and metrics to Neptune\n",
    "    run['parameters/all_parameters'].log(str(space))\n",
    "    run['metrics/mae_scores'].log(str(mae_scores.tolist()))\n",
    "    run[\"metrics/mean_mae\"].log(mean_mae)\n",
    "    run[\"metrics/std_mae\"].log(std_mae)\n",
    "\n",
    "    return {'loss': mean_mae, 'status': STATUS_OK, 'std': std_mae}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Hyperparameter space\n",
    "space = {\n",
    "    'num_leaves': hp.quniform('num_leaves', 20, 1500, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'n_estimators': hp.quniform('n_estimators', 100, 2500, 1),\n",
    "    'min_split_gain': hp.uniform('min_split_gain', 0, 1),\n",
    "    'min_child_weight': hp.uniform('min_child_weight', 0.001, 0.1),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 1, 500, 1),\n",
    "    'subsample': hp.uniform('subsample', 0.25, 1),\n",
    "    'subsample_freq': hp.quniform('subsample_freq', 1, 20, 1),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.25, 1),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.05, 1),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.05, 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caribbean Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trans, X_val_trans, X_holdout_trans, y_train_trans, y_val_trans, y_holdout_trans = cf.import_data(location_name='CARB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Neptune instance\n",
    "run = neptune.init_run(\n",
    "    name=\"RandomForest Reg Caribbean\",\n",
    "    tags=[\"RandomForest\", \"regression\", \"hyperopt\", \"RMSE\", \"Caribbean\", \"CARB\"],\n",
    "    description=\"RandomForest Hyperopt with RMSE on Caribbean\"\n",
    ")\n",
    "\n",
    "# Create the Trials object\n",
    "CARB_trials = Trials()\n",
    "\n",
    "# Create the fmin object\n",
    "CARB_best_hyperparams = fmin(fn = objective,\n",
    "                            space = space,\n",
    "                            algo = tpe.suggest,\n",
    "                            max_evals = 1000,\n",
    "                            trials = CARB_trials,\n",
    "                            show_progressbar=True,\n",
    "                            early_stop_fn=no_progress_loss(100))\n",
    "\n",
    "# Stop Neptune instance\n",
    "run.stop()\n",
    "\n",
    "CARB_best_trial = CARB_trials.best_trial\n",
    "CARB_best_hps = CARB_best_hyperparams.copy()\n",
    "\n",
    "CARB_best_hps['num_leaves'] = int(CARB_best_hps['num_leaves'])\n",
    "CARB_best_hps['n_estimators'] = int(CARB_best_hps['n_estimators'])\n",
    "CARB_best_hps['min_child_samples'] = int(CARB_best_hps['min_child_samples'])\n",
    "CARB_best_hps['subsample_freq'] = int(CARB_best_hps['subsample_freq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the Hyperparameter Search Validation MAE Scores and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the best trial from the search? Report the MAE & StdDev\n",
    "print(f\"Best Mean Absolute Error: {CARB_trials.best_trial['result']['loss']:.4f}\")\n",
    "print(f\"Best Standard Error: {CARB_trials.best_trial['result']['std']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the best hyperparameters\n",
    "CARB_best_hps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recreate the model and get new MAE and Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the model with the best hyperparameters\n",
    "CARB_model = cf.model_score(hps=CARB_best_hps, model_type='lgbm', holdout=True, val=True, Xtt=X_train_trans, ytt=y_train_trans, Xvt=X_val_trans, yvt=y_val_trans, Xht=X_holdout_trans, yht=y_holdout_trans)\n",
    "\n",
    "# Plot the feature importance\n",
    "cf.plot_feat_importance(CARB_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# First run through the feature ablation process\n",
    "# This will determine which features can potentially be removed\n",
    "CARB_feature_ablation_df, CARB_baseline_mae_val, CARB_baseline_mae_train = cf.feat_ablation(\n",
    "    model=CARB_model, hps=CARB_best_hps, model_type='lgbm',\n",
    "    Xtt=X_train_trans, ytt=y_train_trans, \n",
    "    Xvt=X_val_trans, yvt=y_val_trans, \n",
    "    Xht=X_holdout_trans, yht=y_holdout_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the feature ablation dataframe, sorted by the change in MAE to Validation data\n",
    "CARB_feature_ablation_df.sort_values('Val_MAE_Change', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the top 5 features to use in feature ablation combinations\n",
    "CARB_abl_list_to_combo = CARB_feature_ablation_df[CARB_feature_ablation_df['Val_MAE'] <= CARB_baseline_mae_val].sort_values('Val_MAE_Change', ascending=False)['Removed_Feature'].head(1).values[0].split(', ')\n",
    "\n",
    "# Show the top 5 features\n",
    "CARB_abl_list_to_combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Second run through the feature ablation process\n",
    "# This time including the top 5 features whose removal decreased the MAE\n",
    "# These top 5 features will be combined using itertools\n",
    "CARB_feature_ablation_df, CARB_baseline_mae_val, CARB_baseline_mae_train = cf.feat_ablation(\n",
    "    model=CARB_model, hps=CARB_best_hps, model_type='lgbm',\n",
    "    Xtt=X_train_trans, ytt=y_train_trans, \n",
    "    Xvt=X_val_trans, yvt=y_val_trans, \n",
    "    Xht=X_holdout_trans, yht=y_holdout_trans, \n",
    "    abl_list_to_combo=CARB_abl_list_to_combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the feature ablation dataframe, sorted by the change in MAE to Validation data\n",
    "CARB_feature_ablation_df[CARB_feature_ablation_df['Val_MAE'] <= CARB_baseline_mae_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the top 1 feature, which we'll remove.  Might be multiple features, so we split the string\n",
    "CARB_feature_ablation_df[CARB_feature_ablation_df['Val_MAE'] <= CARB_baseline_mae_val].sort_values('Val_MAE_Change', ascending=False)['Removed_Feature'].head(1).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the top features to drop\n",
    "CARB_drop_cols = CARB_feature_ablation_df[CARB_feature_ablation_df['Val_MAE'] <= CARB_baseline_mae_val].sort_values('Val_MAE_Change', ascending=False)['Removed_Feature'].head(1).values[0].split(', ')\n",
    "\n",
    "# Create the feature columns list for saving out\n",
    "CARB_feat_columns = X_train_trans.drop(columns=CARB_drop_cols).columns.to_list()\n",
    "\n",
    "# Recreate the model with the dropped columns\n",
    "# It should have a lower MAE score than the original\n",
    "CARB_experiment_model = cf.model_score(\n",
    "    CARB_best_hps, val=True, model_type='lgbm',\n",
    "    Xtt=X_train_trans.drop(columns=CARB_drop_cols), ytt=y_train_trans, \n",
    "    Xvt=X_val_trans.drop(columns=CARB_drop_cols), yvt=y_val_trans, \n",
    "    Xht=X_holdout_trans.drop(columns=CARB_drop_cols), yht=y_holdout_trans)\n",
    "\n",
    "# Plot the feature importance for this model\n",
    "cf.plot_feat_importance(CARB_experiment_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output the Model, Trials, Parameters and Feature List to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the model artifacts to disk\n",
    "cf.write_out(model=CARB_model, trials=CARB_trials, params=CARB_best_hps, feat_cols=CARB_feat_columns, model_family='lightgbm_reg', location_name='CARB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Holdout Truth vs Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = y_val_trans.copy(deep=True)\n",
    "CARB_val_pred = CARB_model.predict(X_val_trans)\n",
    "eval_df['predictions'] = CARB_val_pred.tolist()\n",
    "eval_df['diff'] = eval_df['y_val'] - eval_df['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.sort_values(by='diff', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(eval_df[eval_df['y_val'] > 5], x='diff', nbins=100, title='Distribution of the diff between prediction and holdout where true value > 5')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_df[(eval_df['diff'].between(-5,5))]\n",
    "#eval_df[(eval_df['diff'].between(-5,5)) & (eval_df['y_val'] > 5)]\n",
    "eval_df[~(eval_df['diff'].between(-5,5))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SHAP Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# CARB_X_val_trans = X_val_trans.copy(deep=True)\n",
    "# CARB_y_val_trans = y_val_trans.copy(deep=True)\n",
    "# explainer = shap.TreeExplainer(CARB_model)\n",
    "# shap_values = explainer(CARB_X_val_trans)\n",
    "# shap_interaction = explainer.shap_interaction_values(CARB_X_val_trans)\n",
    "# sv = explainer.shap_values(CARB_X_val_trans)\n",
    "# shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beeswarm Importance\n",
    "# plt.figure(figsize=(8,6))\n",
    "# plt.title(f\"SHAP Beeswarm Analysis\")\n",
    "# shap.plots.beeswarm(shap_values, max_display=32)\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate Individual Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#investigate = CARB_X_val_trans.index.get_loc(5809)\n",
    "# print(CARB_y_val_trans.iloc[investigate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waterfall on a prediction\n",
    "# plt.figure(figsize=(8,6))\n",
    "# shap.plots.waterfall(shap_values[investigate], max_display=20) # , show=False\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision plot on a prediction\n",
    "# shap.decision_plot(explainer.expected_value, explainer.shap_values(CARB_X_val_trans)[investigate], CARB_X_val_trans, feature_display_range=slice(-1,-51,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# South East Asia and Australia Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trans, X_val_trans, X_holdout_trans, y_train_trans, y_val_trans, y_holdout_trans = cf.import_data(location_name='SEAA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Neptune instance\n",
    "run = neptune.init_run(\n",
    "    name=\"LightGBM Reg South East Asia and Australia\",\n",
    "    tags=[\"LightGBM\", \"regression\", \"hyperopt\", \"RMSE\", \"South East Asia and Australia\", \"SEAA\"],\n",
    "    description=\"LightGBM Hyperopt with RMSE on South East Asia and Australia\"\n",
    ")\n",
    "\n",
    "# Create the Trials object\n",
    "SEAA_trials = Trials()\n",
    "\n",
    "# Create the fmin object\n",
    "SEAA_best_hyperparams = fmin(fn = objective,\n",
    "                            space = space,\n",
    "                            algo = tpe.suggest,\n",
    "                            max_evals = 1000,\n",
    "                            trials = SEAA_trials,\n",
    "                            show_progressbar=True,\n",
    "                            early_stop_fn=no_progress_loss(100))\n",
    "\n",
    "# Stop Neptune instance\n",
    "run.stop()\n",
    "\n",
    "SEAA_best_trial = SEAA_trials.best_trial\n",
    "SEAA_best_hps = SEAA_best_hyperparams.copy()\n",
    "\n",
    "SEAA_best_hps['num_leaves'] = int(SEAA_best_hps['num_leaves'])\n",
    "SEAA_best_hps['n_estimators'] = int(SEAA_best_hps['n_estimators'])\n",
    "SEAA_best_hps['min_child_samples'] = int(SEAA_best_hps['min_child_samples'])\n",
    "SEAA_best_hps['subsample_freq'] = int(SEAA_best_hps['subsample_freq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the Hyperparameter Search Validation MAE Scores and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the best trial from the search? Report the MAE & StdDev\n",
    "print(f\"Best Mean Absolute Error: {SEAA_trials.best_trial['result']['loss']:.4f}\")\n",
    "print(f\"Best Standard Error: {SEAA_trials.best_trial['result']['std']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the best hyperparameters\n",
    "SEAA_best_hps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recreate the model and get new MAE and Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the model with the best hyperparameters\n",
    "SEAA_model = cf.model_score(hps=SEAA_best_hps, model_type='lgbm', holdout=True, val=True, Xtt=X_train_trans, ytt=y_train_trans, Xvt=X_val_trans, yvt=y_val_trans, Xht=X_holdout_trans, yht=y_holdout_trans)\n",
    "\n",
    "# Plot the feature importance\n",
    "cf.plot_feat_importance(SEAA_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# First run through the feature ablation process\n",
    "# This will determine which features can potentially be removed\n",
    "SEAA_feature_ablation_df, SEAA_baseline_mae_val, SEAA_baseline_mae_train = cf.feat_ablation(\n",
    "    model=SEAA_model, hps=SEAA_best_hps, model_type='lgbm',\n",
    "    Xtt=X_train_trans, ytt=y_train_trans, \n",
    "    Xvt=X_val_trans, yvt=y_val_trans, \n",
    "    Xht=X_holdout_trans, yht=y_holdout_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the feature ablation dataframe, sorted by the change in MAE to Validation data\n",
    "SEAA_feature_ablation_df.sort_values('Val_MAE_Change', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the top 5 features to use in feature ablation combinations\n",
    "SEAA_abl_list_to_combo = SEAA_feature_ablation_df[SEAA_feature_ablation_df['Val_MAE'] <= SEAA_baseline_mae_val].sort_values('Val_MAE_Change', ascending=False)['Removed_Feature'].head(5).to_list()\n",
    "\n",
    "# Review the list\n",
    "SEAA_abl_list_to_combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Second run through the feature ablation process\n",
    "# This time including the top 5 features whose removal decreased the MAE\n",
    "# These top 5 features will be combined using itertools\n",
    "SEAA_feature_ablation_df, SEAA_baseline_mae_val, SEAA_baseline_mae_train = cf.feat_ablation(\n",
    "    model=SEAA_model, hps=SEAA_best_hps, model_type='lgbm',\n",
    "    Xtt=X_train_trans, ytt=y_train_trans, \n",
    "    Xvt=X_val_trans, yvt=y_val_trans, \n",
    "    Xht=X_holdout_trans, yht=y_holdout_trans, \n",
    "    abl_list_to_combo=SEAA_abl_list_to_combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the feature ablation dataframe, sorted by the change in MAE to Validation data\n",
    "SEAA_feature_ablation_df[SEAA_feature_ablation_df['Val_MAE'] <= SEAA_baseline_mae_val].sort_values('Val_MAE_Change', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the top 1 feature, which we'll remove.  Might be multiple features, so we split the string\n",
    "SEAA_feature_ablation_df[SEAA_feature_ablation_df['Val_MAE'] <= SEAA_baseline_mae_val].sort_values('Val_MAE_Change', ascending=False)['Removed_Feature'].head(1).values[0].split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the top features to drop\n",
    "SEAA_drop_cols = SEAA_feature_ablation_df[SEAA_feature_ablation_df['Val_MAE'] <= SEAA_baseline_mae_val].sort_values('Val_MAE_Change', ascending=False)['Removed_Feature'].head(1).values[0].split(', ')\n",
    "\n",
    "# Create the feature columns list for saving out\n",
    "SEAA_feat_columns = X_train_trans.drop(columns=SEAA_drop_cols).columns.to_list()\n",
    "\n",
    "# Recreate the model with the dropped columns\n",
    "# It should have a lower MAE score than the original\n",
    "SEAA_experiment_model = cf.model_score(\n",
    "    SEAA_best_hps, val=True, model_type='lgbm', \n",
    "    Xtt=X_train_trans.drop(columns=SEAA_drop_cols), ytt=y_train_trans, \n",
    "    Xvt=X_val_trans.drop(columns=SEAA_drop_cols), yvt=y_val_trans, \n",
    "    Xht=X_holdout_trans.drop(columns=SEAA_drop_cols), yht=y_holdout_trans)\n",
    "\n",
    "# Plot the feature importance for this model\n",
    "cf.plot_feat_importance(SEAA_experiment_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output the Model, Trials, Parameters and Feature List to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the model artifacts to disk\n",
    "cf.write_out(model=SEAA_model, trials=SEAA_trials, params=SEAA_best_hps, feat_cols=SEAA_feat_columns, model_family='lightgbm_reg', location_name='SEAA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Holdout Truth vs Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = y_val_trans.copy(deep=True)\n",
    "SEAA_val_pred = SEAA_model.predict(X_val_trans)\n",
    "eval_df['predictions'] = SEAA_val_pred.tolist()\n",
    "eval_df['diff'] = eval_df['y_val'] - eval_df['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.sort_values(by='diff', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(eval_df[eval_df['y_val'] > 5], x='diff', nbins=100, title='Distribution of the diff between prediction and holdout where true value > 5')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_df[(eval_df['diff'].between(-5,5))]\n",
    "#eval_df[(eval_df['diff'].between(-5,5)) & (eval_df['y_val'] > 5)]\n",
    "eval_df[~(eval_df['diff'].between(-5,5))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SHAP Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# SEAA_X_val_trans = X_val_trans.copy(deep=True)\n",
    "# SEAA_y_val_trans = y_val_trans.copy(deep=True)\n",
    "# explainer = shap.TreeExplainer(SEAA_model)\n",
    "# shap_values = explainer(SEAA_X_val_trans)\n",
    "# shap_interaction = explainer.shap_interaction_values(SEAA_X_val_trans)\n",
    "# sv = explainer.shap_values(SEAA_X_val_trans)\n",
    "# shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beeswarm Importance\n",
    "# plt.figure(figsize=(8,6))\n",
    "# plt.title(f\"SHAP Beeswarm Analysis\")\n",
    "# shap.plots.beeswarm(shap_values, max_display=32)\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate Individual Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#investigate = SEAA_X_val_trans.index.get_loc(5809)\n",
    "# print(SEAA_y_val_trans.iloc[investigate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waterfall on a prediction\n",
    "# plt.figure(figsize=(8,6))\n",
    "# shap.plots.waterfall(shap_values[investigate], max_display=20) # , show=False\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision plot on a prediction\n",
    "# shap.decision_plot(explainer.expected_value, explainer.shap_values(SEAA_X_val_trans)[investigate], SEAA_X_val_trans, feature_display_range=slice(-1,-51,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trans, X_val_trans, X_holdout_trans, y_train_trans, y_val_trans, y_holdout_trans = cf.import_data(location_name='GLOB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Neptune instance\n",
    "run = neptune.init_run(\n",
    "    name=\"LightGBM Reg Global\",\n",
    "    tags=[\"LightGBM\", \"regression\", \"hyperopt\", \"MAE\", \"Global\", \"GLOB\"],\n",
    "    description=\"LightGBM Hyperopt with MAE on Global\"\n",
    ")\n",
    "\n",
    "# Create the Trials object\n",
    "GLOB_trials = Trials()\n",
    "\n",
    "# Create the fmin object\n",
    "GLOB_best_hyperparams = fmin(fn = objective,\n",
    "                            space = space,\n",
    "                            algo = tpe.suggest,\n",
    "                            max_evals = 1000,\n",
    "                            trials = GLOB_trials,\n",
    "                            show_progressbar=True,\n",
    "                            early_stop_fn=no_progress_loss(100))\n",
    "\n",
    "# Stop Neptune instance\n",
    "run.stop()\n",
    "\n",
    "GLOB_best_trial = GLOB_trials.best_trial\n",
    "GLOB_best_hps = GLOB_best_hyperparams.copy()\n",
    "\n",
    "GLOB_best_hps['num_leaves'] = int(GLOB_best_hps['num_leaves'])\n",
    "GLOB_best_hps['n_estimators'] = int(GLOB_best_hps['n_estimators'])\n",
    "GLOB_best_hps['min_child_samples'] = int(GLOB_best_hps['min_child_samples'])\n",
    "GLOB_best_hps['subsample_freq'] = int(GLOB_best_hps['subsample_freq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the Hyperparameter Search Validation MAE Scores and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the best trial from the search? Report the MAE & StdDev\n",
    "print(f\"Best Mean Absolute Error: {GLOB_trials.best_trial['result']['loss']:.4f}\")\n",
    "print(f\"Best Standard Error: {GLOB_trials.best_trial['result']['std']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the best hyperparameters\n",
    "GLOB_best_hps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recreate the model and get new MAE and Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the model with the best hyperparameters\n",
    "GLOB_model = cf.model_score(hps=GLOB_best_hps, model_type='lgbm', holdout=True, val=True, Xtt=X_train_trans, ytt=y_train_trans, Xvt=X_val_trans, yvt=y_val_trans, Xht=X_holdout_trans, yht=y_holdout_trans)\n",
    "\n",
    "# Plot the feature importance\n",
    "cf.plot_feat_importance(GLOB_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# First run through the feature ablation process\n",
    "# This will determine which features can potentially be removed\n",
    "GLOB_feature_ablation_df, GLOB_baseline_mae_val, GLOB_baseline_mae_train = cf.feat_ablation(\n",
    "    model=GLOB_model, hps=GLOB_best_hps, model_type='lgbm',\n",
    "    Xtt=X_train_trans, ytt=y_train_trans, \n",
    "    Xvt=X_val_trans, yvt=y_val_trans, \n",
    "    Xht=X_holdout_trans, yht=y_holdout_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the feature ablation dataframe, sorted by the change in MAE to Validation data\n",
    "GLOB_feature_ablation_df.sort_values('Val_MAE_Change', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the top 5 features to use in feature ablation combinations\n",
    "GLOB_abl_list_to_combo = GLOB_feature_ablation_df[GLOB_feature_ablation_df['Val_MAE'] <= GLOB_baseline_mae_val].sort_values('Val_MAE_Change', ascending=False)['Removed_Feature'].head(5).to_list()\n",
    "\n",
    "# Review the list\n",
    "GLOB_abl_list_to_combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Second run through the feature ablation process\n",
    "# This time including the top 5 features whose removal decreased the MAE\n",
    "# These top 5 features will be combined using itertools\n",
    "GLOB_feature_ablation_df, GLOB_baseline_mae_val, GLOB_baseline_mae_train = cf.feat_ablation(\n",
    "    model=GLOB_model, hps=GLOB_best_hps, model_type='lgbm',\n",
    "    Xtt=X_train_trans, ytt=y_train_trans, \n",
    "    Xvt=X_val_trans, yvt=y_val_trans, \n",
    "    Xht=X_holdout_trans, yht=y_holdout_trans, \n",
    "    abl_list_to_combo=GLOB_abl_list_to_combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the feature ablation dataframe, sorted by the change in MAE to Validation data\n",
    "GLOB_feature_ablation_df[GLOB_feature_ablation_df['Val_MAE'] <= GLOB_baseline_mae_val].sort_values('Val_MAE_Change', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the top 1 feature, which we'll remove.  Might be multiple features, so we split the string\n",
    "GLOB_feature_ablation_df[GLOB_feature_ablation_df['Val_MAE'] <= GLOB_baseline_mae_val].sort_values('Val_MAE_Change', ascending=False)['Removed_Feature'].head(1).values[0].split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the top features to drop\n",
    "GLOB_drop_cols = GLOB_feature_ablation_df[GLOB_feature_ablation_df['Val_MAE'] <= GLOB_baseline_mae_val].sort_values('Val_MAE_Change', ascending=False)['Removed_Feature'].head(1).values[0].split(', ')\n",
    "\n",
    "# Create the feature columns list for saving out\n",
    "GLOB_feat_columns = X_train_trans.drop(columns=GLOB_drop_cols).columns.to_list()\n",
    "\n",
    "# Recreate the model with the dropped columns\n",
    "# It should have a lower MAE score than the original\n",
    "GLOB_experiment_model = cf.model_score(\n",
    "    GLOB_best_hps, val=True, model_type='lgbm', \n",
    "    Xtt=X_train_trans.drop(columns=GLOB_drop_cols), ytt=y_train_trans, \n",
    "    Xvt=X_val_trans.drop(columns=GLOB_drop_cols), yvt=y_val_trans, \n",
    "    Xht=X_holdout_trans.drop(columns=GLOB_drop_cols), yht=y_holdout_trans)\n",
    "\n",
    "# Plot the feature importance for this model\n",
    "cf.plot_feat_importance(GLOB_experiment_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output the Model, Trials, Parameters and Feature List to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the model artifacts to disk\n",
    "cf.write_out(model=GLOB_model, trials=GLOB_trials, params=GLOB_best_hps, feat_cols=GLOB_feat_columns, model_family='lightgbm_reg', location_name='GLOB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Holdout Truth vs Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = y_val_trans.copy(deep=True)\n",
    "GLOB_val_pred = GLOB_model.predict(X_val_trans)\n",
    "eval_df['predictions'] = GLOB_val_pred.tolist()\n",
    "eval_df['diff'] = eval_df['y_val'] - eval_df['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.sort_values(by='diff', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(eval_df[eval_df['y_val'] > 5], x='diff', nbins=100, title='Distribution of the diff between prediction and holdout where true value > 5')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_df[(eval_df['diff'].between(-5,5))]\n",
    "#eval_df[(eval_df['diff'].between(-5,5)) & (eval_df['y_val'] > 5)]\n",
    "eval_df[~(eval_df['diff'].between(-5,5))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SHAP Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# GLOB_X_val_trans = X_val_trans.copy(deep=True)\n",
    "# GLOB_y_val_trans = y_val_trans.copy(deep=True)\n",
    "# explainer = shap.TreeExplainer(GLOB_model)\n",
    "# shap_values = explainer(GLOB_X_val_trans)\n",
    "# shap_interaction = explainer.shap_interaction_values(GLOB_X_val_trans)\n",
    "# sv = explainer.shap_values(GLOB_X_val_trans)\n",
    "# shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beeswarm Importance\n",
    "# plt.figure(figsize=(8,6))\n",
    "# plt.title(f\"SHAP Beeswarm Analysis\")\n",
    "# shap.plots.beeswarm(shap_values, max_display=32)\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate Individual Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#investigate = GLOB_X_val_trans.index.get_loc(5809)\n",
    "# print(GLOB_y_val_trans.iloc[investigate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waterfall on a prediction\n",
    "# plt.figure(figsize=(8,6))\n",
    "# shap.plots.waterfall(shap_values[investigate], max_display=20) # , show=False\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision plot on a prediction\n",
    "# shap.decision_plot(explainer.expected_value, explainer.shap_values(GLOB_X_val_trans)[investigate], GLOB_X_val_trans, feature_display_range=slice(-1,-51,-1))"
   ]
  }
 ],
 "metadata": {
  "deepnote_app_layout": "powerful-article",
  "deepnote_app_reactivity_enabled": true,
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "43bb9e87602f43feaea2aaa5e7f16263",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
