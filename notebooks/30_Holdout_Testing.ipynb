{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [],
    "deepnote_app_block_visible": false,
    "cell_id": "771edba3abe646df908b4d7c28f22126",
    "deepnote_cell_type": "text-cell-h1"
   },
   "source": [
    "# Holdout Testing"
   ],
   "block_group": "39ebf4ea1303430b8b9a076515cdf76f"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "aef1439e3b0f46a8a8b24390a0b0e0a7",
    "deepnote_cell_type": "text-cell-h2"
   },
   "source": [
    "## Notebook Setup"
   ],
   "block_group": "de218e21dadf49d192c64b7b9e0a174e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Import Standard Libraries\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import custom functions\n",
    "import env_functions as ef\n",
    "import s3_functions as sf\n",
    "import common_functions as cf"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Import Modeling Libraries\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Import Metrics\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Determine the environment and get appropriate vars\n",
    "deepnote, env_vars = ef.load_env_vars()\n",
    "\n",
    "# Iterate through the vars and set them as global vars\n",
    "for var_name, var in env_vars.items():\n",
    "    globals()[var_name] = var\n",
    "\n",
    "# If not in the DeepNote environment, create a dict for aws creds\n",
    "#   that were located in the environment file.  This will be passed\n",
    "#   to all aws s3 functions.\n",
    "if not deepnote:\n",
    "    aws_env_vars = {\n",
    "        'access_key_id': aws_access_key_id,\n",
    "        'secret_access_key': aws_secret_access_key,\n",
    "        'bucket_name': s3_bucket_name\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Pandas Configs\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "# Ignore Warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', category=FutureWarning)\n",
    "warnings.simplefilter('ignore', category=UserWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "CARB_Xtt, CARB_Xvt, CARB_Xht, CARB_yt, CARB_yv, CARB_yh = cf.import_data(location_name='CARB')\n",
    "SEAA_Xtt, SEAA_Xvt, SEAA_Xht, SEAA_yt, SEAA_yv, SEAA_yh = cf.import_data(location_name='SEAA')\n",
    "GLOB_Xtt, GLOB_Xvt, GLOB_Xht, GLOB_yt, GLOB_yv, GLOB_yh = cf.import_data(location_name='GLOB')\n",
    "\n",
    "if deepnote:\n",
    "    # Load XGB Features\n",
    "    with open('/work/data/Feature_Selection/CARB_XGB_feat_list.pkl', 'rb') as f:\n",
    "        CARB_XGB_feat_list =  pickle.load(f)\n",
    "    with open('/work/data/Feature_Selection/SEAA_XGB_feat_list.pkl', 'rb') as f:\n",
    "        SEAA_XGB_feat_list =  pickle.load(f)\n",
    "    with open('/work/data/Feature_Selection/GLOB_XGB_feat_list.pkl', 'rb') as f:\n",
    "        GLOB_XGB_feat_list =  pickle.load(f)\n",
    "\n",
    "    # Load LGBM Features\n",
    "    with open('/work/data/Feature_Selection/CARB_LGBM_feat_list.pkl', 'rb') as f:\n",
    "        CARB_LGBM_feat_list =  pickle.load(f)\n",
    "    with open('/work/data/Feature_Selection/SEAA_LGBM_feat_list.pkl', 'rb') as f:\n",
    "        SEAA_LGBM_feat_list =  pickle.load(f)\n",
    "    with open('/work/data/Feature_Selection/GLOB_LGBM_feat_list.pkl', 'rb') as f:\n",
    "        GLOB_LGBM_feat_list =  pickle.load(f)\n",
    "else:\n",
    "    # Load XGB Features\n",
    "    f = sf.load_from_s3(file_path='data/Feature_Selection/CARB_XGB_feat_list.pkl', **aws_env_vars)\n",
    "    CARB_XGB_feat_list = pickle.load(f)\n",
    "    f = sf.load_from_s3(file_path='data/Feature_Selection/SEAA_XGB_feat_list.pkl', **aws_env_vars)\n",
    "    SEAA_XGB_feat_list = pickle.load(f)\n",
    "    f = sf.load_from_s3(file_path='data/Feature_Selection/GLOB_XGB_feat_list.pkl', **aws_env_vars)\n",
    "    GLOB_XGB_feat_list = pickle.load(f)\n",
    "    \n",
    "    # Load LGBM Features\n",
    "    f = sf.load_from_s3(file_path='data/Feature_Selection/CARB_LGBM_feat_list.pkl', **aws_env_vars)\n",
    "    CARB_LGBM_feat_list = pickle.load(f)\n",
    "    f = sf.load_from_s3(file_path='data/Feature_Selection/SEAA_LGBM_feat_list.pkl', **aws_env_vars)\n",
    "    SEAA_LGBM_feat_list = pickle.load(f)\n",
    "    f = sf.load_from_s3(file_path='data/Feature_Selection/GLOB_LGBM_feat_list.pkl', **aws_env_vars)\n",
    "    GLOB_LGBM_feat_list = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Models and Parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if deepnote:\n",
    "    # Fetch model parameters\n",
    "    with open(\"/work/models/xgboost_reg/CARB/20240413_185012_params.pkl\", \"rb\") as f:\n",
    "        CARB_XGB_params = pickle.load(f)\n",
    "    with open(\"/work/models/xgboost_reg/SEAA/20240413_191526_params.pkl\", \"rb\") as f:\n",
    "        SEAA_XGB_params = pickle.load(f)\n",
    "    with open(\"/work/models/xgboost_reg/GLOB/20240413_195305_params.pkl\", \"rb\") as f:\n",
    "        GLOB_XGB_params = pickle.load(f)\n",
    "\n",
    "    # Fetch model objects\n",
    "    with open(\"/work/models/xgboost_reg/CARB/20240413_185012_model.pkl\", \"rb\") as f:\n",
    "        CARB_XGB_model = pickle.load(f)\n",
    "    with open(\"/work/models/xgboost_reg/SEAA/20240413_191526_model.pkl\", \"rb\") as f:\n",
    "        SEAA_XGB_model = pickle.load(f)\n",
    "    with open(\"/work/models/xgboost_reg/GLOB/20240413_195305_model.pkl\", \"rb\") as f:\n",
    "        GLOB_XGB_model = pickle.load(f)\n",
    "\n",
    "else:\n",
    "    # Fetch model parameters\n",
    "    f = sf.load_from_s3(file_path=\"models/xgboost_reg/CARB/20240413_185012_params.pkl\", **aws_env_vars)\n",
    "    CARB_XGB_params = pickle.load(f)\n",
    "    f = sf.load_from_s3(file_path=\"models/xgboost_reg/SEAA/20240413_191526_params.pkl\", **aws_env_vars)\n",
    "    SEAA_XGB_params = pickle.load(f)\n",
    "    f = sf.load_from_s3(file_path=\"models/xgboost_reg/GLOB/20240413_195305_params.pkl\", **aws_env_vars)\n",
    "    GLOB_XGB_params = pickle.load(f)\n",
    "\n",
    "    # Fetch model objects\n",
    "    f = sf.load_from_s3(file_path=\"models/xgboost_reg/CARB/20240413_185012_model.pkl\", **aws_env_vars)\n",
    "    CARB_XGB_model = pickle.load(f)\n",
    "    f = sf.load_from_s3(file_path=\"models/xgboost_reg/SEAA/20240413_191526_model.pkl\", **aws_env_vars)\n",
    "    SEAA_XGB_model = pickle.load(f)\n",
    "    f = sf.load_from_s3(file_path=\"models/xgboost_reg/GLOB/20240413_195305_model.pkl\", **aws_env_vars)\n",
    "    GLOB_XGB_model = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LightGBM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if deepnote:\n",
    "    # Fetch model parameters\n",
    "    with open(\"/work/models/lightgbm_reg/CARB/20240413_195656_params.pkl\", \"rb\") as f:\n",
    "        CARB_LGBM_params = pickle.load(f)\n",
    "    with open(\"/work/models/lightgbm_reg/SEAA/20240413_210139_params.pkl\", \"rb\") as f:\n",
    "        SEAA_LGBM_params = pickle.load(f)\n",
    "    with open(\"/work/models/lightgbm_reg/GLOB/20240414_113645_params.pkl\", \"rb\") as f:\n",
    "        GLOB_LGBM_params = pickle.load(f)\n",
    "\n",
    "    # Fetch model objects\n",
    "    with open(\"/work/models/lightgbm_reg/CARB/20240413_195656_model.pkl\", \"rb\") as f:\n",
    "        CARB_LGBM_model = pickle.load(f)\n",
    "    with open(\"/work/models/lightgbm_reg/SEAA/20240413_210139_model.pkl\", \"rb\") as f:\n",
    "        SEAA_LGBM_model = pickle.load(f)\n",
    "    with open(\"/work/models/lightgbm_reg/GLOB/20240414_113645_model.pkl\", \"rb\") as f:\n",
    "        GLOB_LGBM_model = pickle.load(f)\n",
    "\n",
    "else:\n",
    "    # Fetch model parameters\n",
    "    f = sf.load_from_s3(file_path=\"models/lightgbm_reg/CARB/20240413_195656_params.pkl\", **aws_env_vars)\n",
    "    CARB_LGBM_params = pickle.load(f)\n",
    "    f = sf.load_from_s3(file_path=\"models/lightgbm_reg/SEAA/20240413_210139_params.pkl\", **aws_env_vars)\n",
    "    SEAA_LGBM_params = pickle.load(f)\n",
    "    f = sf.load_from_s3(file_path=\"models/lightgbm_reg/GLOB/20240414_113645_params.pkl\", **aws_env_vars)\n",
    "    GLOB_LGBM_params = pickle.load(f)\n",
    "\n",
    "\n",
    "    # Fetch model objects\n",
    "    f = sf.load_from_s3(file_path=\"models/lightgbm_reg/CARB/20240413_195656_model.pkl\", **aws_env_vars)\n",
    "    CARB_LGBM_model = pickle.load(f)\n",
    "    f = sf.load_from_s3(file_path=\"models/lightgbm_reg/SEAA/20240413_210139_model.pkl\", **aws_env_vars)\n",
    "    SEAA_LGBM_model = pickle.load(f)\n",
    "    f = sf.load_from_s3(file_path=\"models/lightgbm_reg/GLOB/20240414_113645_model.pkl\", **aws_env_vars)\n",
    "    GLOB_LGBM_model = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RandomForest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if deepnote:\n",
    "    # Fetch model parameters\n",
    "    with open(\"/work/models/randomforest_reg/CARB/20240413_111331_params.pkl\", \"rb\") as f:\n",
    "        CARB_RF_params = pickle.load(f)\n",
    "    with open(\"/work/models/randomforest_reg/SEAA/20240413_115032_params.pkl\", \"rb\") as f:\n",
    "        SEAA_RF_params = pickle.load(f)\n",
    "    with open(\"/work/models/randomforest_reg/GLOB/20240413_135029_params.pkl\", \"rb\") as f:\n",
    "        GLOB_RF_params = pickle.load(f)\n",
    "\n",
    "    # Fetch model objects\n",
    "    with open(\"/work/models/randomforest_reg/CARB/20240413_111331_model.pkl\", \"rb\") as f:\n",
    "        CARB_RF_model = pickle.load(f)\n",
    "    with open(\"/work/models/randomforest_reg/SEAA/20240413_115032_model.pkl\", \"rb\") as f:\n",
    "        SEAA_RF_model = pickle.load(f)\n",
    "    with open(\"/work/models/randomforest_reg/GLOB/20240413_135029_model.pkl\", \"rb\") as f:\n",
    "        GLOB_RF_model = pickle.load(f)\n",
    "        \n",
    "else:\n",
    "    # Fetch model parameters\n",
    "    f = sf.load_from_s3(file_path=\"models/randomforest_reg/CARB/20240413_111331_params.pkl\", **aws_env_vars)\n",
    "    CARB_RF_params = pickle.load(f)\n",
    "    f = sf.load_from_s3(file_path=\"models/randomforest_reg/SEAA/20240413_115032_params.pkl\", **aws_env_vars)\n",
    "    SEAA_RF_params = pickle.load(f)\n",
    "    f = sf.load_from_s3(file_path=\"models/randomforest_reg/GLOB/20240413_135029_params.pkl\", **aws_env_vars)\n",
    "    GLOB_RF_params = pickle.load(f)\n",
    "\n",
    "\n",
    "    # Fetch model objects\n",
    "    f = sf.load_from_s3(file_path=\"models/randomforest_reg/CARB/20240413_111331_model.pkl\", **aws_env_vars)\n",
    "    CARB_RF_model = pickle.load(f)\n",
    "    f = sf.load_from_s3(file_path=\"models/randomforest_reg/SEAA/20240413_115032_model.pkl\", **aws_env_vars)\n",
    "    SEAA_RF_model = pickle.load(f)\n",
    "    f = sf.load_from_s3(file_path=\"models/randomforest_reg/GLOB/20240413_135029_model.pkl\", **aws_env_vars)\n",
    "    GLOB_RF_model = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ElasticNet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if deepnote:\n",
    "    # Fetch model parameters\n",
    "    with open(\"/work/models/elasticnet_reg/CARB/20240413_135638_params.pkl\", \"rb\") as f:\n",
    "        CARB_ENET_params = pickle.load(f)\n",
    "    with open(\"/work/models/elasticnet_reg/SEAA/20240413_135843_params.pkl\", \"rb\") as f:\n",
    "        SEAA_ENET_params = pickle.load(f)\n",
    "    with open(\"/work/models/elasticnet_reg/GLOB/20240413_140053_params.pkl\", \"rb\") as f:\n",
    "        GLOB_ENET_params = pickle.load(f)\n",
    "\n",
    "    # Fetch model objects\n",
    "    with open(\"/work/models/elasticnet_reg/CARB/20240413_135638_model.pkl\", \"rb\") as f:\n",
    "        CARB_ENET_model = pickle.load(f)\n",
    "    with open(\"/work/models/elasticnet_reg/SEAA/20240413_135843_model.pkl\", \"rb\") as f:\n",
    "        SEAA_ENET_model = pickle.load(f)\n",
    "    with open(\"/work/models/elasticnet_reg/GLOB/20240413_140053_model.pkl\", \"rb\") as f:\n",
    "        GLOB_ENET_model = pickle.load(f)\n",
    "        \n",
    "else:\n",
    "    # Fetch model parameters\n",
    "    f = sf.load_from_s3(file_path=\"models/elasticnet_reg/CARB/20240413_135638_params.pkl\", **aws_env_vars)\n",
    "    CARB_ENET_params = pickle.load(f)\n",
    "    f = sf.load_from_s3(file_path=\"models/elasticnet_reg/SEAA/20240413_135843_params.pkl\", **aws_env_vars)\n",
    "    SEAA_ENET_params = pickle.load(f)\n",
    "    f = sf.load_from_s3(file_path=\"models/elasticnet_reg/GLOB/20240413_140053_params.pkl\", **aws_env_vars)\n",
    "    GLOB_ENET_params = pickle.load(f)\n",
    "\n",
    "\n",
    "    # Fetch model objects\n",
    "    f = sf.load_from_s3(file_path=\"models/elasticnet_reg/CARB/20240413_135638_model.pkl\", **aws_env_vars)\n",
    "    CARB_ENET_model = pickle.load(f)\n",
    "    f = sf.load_from_s3(file_path=\"models/elasticnet_reg/SEAA/20240413_135843_model.pkl\", **aws_env_vars)\n",
    "    SEAA_ENET_model = pickle.load(f)\n",
    "    f = sf.load_from_s3(file_path=\"models/elasticnet_reg/GLOB/20240413_140053_model.pkl\", **aws_env_vars)\n",
    "    GLOB_ENET_model = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## HistGradientBoosting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if deepnote:\n",
    "    # Fetch model parameters\n",
    "    with open(\"/work/models/histgradboost_reg/CARB/20240413_154115_params.pkl\", \"rb\") as f:\n",
    "        CARB_HGBM_params = pickle.load(f)\n",
    "    with open(\"/work/models/histgradboost_reg/SEAA/20240413_165035_params.pkl\", \"rb\") as f:\n",
    "        SEAA_HGBM_params = pickle.load(f)\n",
    "    with open(\"/work/models/histgradboost_reg/GLOB/20240413_202923_params.pkl\", \"rb\") as f:\n",
    "        GLOB_HGBM_params = pickle.load(f)\n",
    "\n",
    "    # Fetch model objects\n",
    "    with open(\"/work/models/histgradboost_reg/CARB/20240413_154115_model.pkl\", \"rb\") as f:\n",
    "        CARB_HGBM_model = pickle.load(f)\n",
    "    with open(\"/work/models/histgradboost_reg/SEAA/20240413_165035_model.pkl\", \"rb\") as f:\n",
    "        SEAA_HGBM_model = pickle.load(f)\n",
    "    with open(\"/work/models/histgradboost_reg/GLOB/20240413_202923_model.pkl\", \"rb\") as f:\n",
    "        GLOB_HGBM_model = pickle.load(f)\n",
    "        \n",
    "else:\n",
    "    # Fetch model parameters\n",
    "    f = sf.load_from_s3(file_path=\"models/histgradboost_reg/CARB/20240413_154115_params.pkl\", **aws_env_vars)\n",
    "    CARB_HGBM_params = pickle.load(f)\n",
    "    f = sf.load_from_s3(file_path=\"models/histgradboost_reg/SEAA/20240413_165035_params.pkl\", **aws_env_vars)\n",
    "    SEAA_HGBM_params = pickle.load(f)\n",
    "    f = sf.load_from_s3(file_path=\"models/histgradboost_reg/GLOB/20240413_202923_params.pkl\", **aws_env_vars)\n",
    "    GLOB_HGBM_params = pickle.load(f)\n",
    "\n",
    "\n",
    "    # Fetch model objects\n",
    "    f = sf.load_from_s3(file_path=\"models/histgradboost_reg/CARB/20240413_154115_model.pkl\", **aws_env_vars)\n",
    "    CARB_HGBM_model = pickle.load(f)\n",
    "    f = sf.load_from_s3(file_path=\"models/histgradboost_reg/SEAA/20240413_165035_model.pkl\", **aws_env_vars)\n",
    "    SEAA_HGBM_model = pickle.load(f)\n",
    "    f = sf.load_from_s3(file_path=\"models/histgradboost_reg/GLOB/20240413_202923_model.pkl\", **aws_env_vars)\n",
    "    GLOB_HGBM_model = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Holdout Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def model_prediction(model, X, y, region=None, features=None):\n",
    "    \"\"\"\n",
    "    This function takes a trained model and a test set and returns the predicted values, \n",
    "    the mean absolute error, the root mean squared error, and the R-squared score.\n",
    "    \"\"\"\n",
    "\n",
    "    if features is not None:\n",
    "        X = X[features]\n",
    "\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred = np.clip(y_pred, 0, 100)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    rmse = mean_squared_error(y, y_pred, squared=False)\n",
    "    rsq = r2_score(y, y_pred)\n",
    "    feats = X.columns.tolist()\n",
    "\n",
    "    return y_pred, mae, rmse, rsq, feats\n",
    "\n",
    "\n",
    "def dummy_model_prediction(X, y):\n",
    "    \"\"\"\n",
    "    This function takes an X, y set and returns the predicted values\n",
    "    using a dummy model, the mean absolute error, the root mean squared error,\n",
    "    and the R-squared score.\n",
    "    \"\"\" \n",
    "    model = DummyRegressor(strategy='mean')\n",
    "    model.fit(X, y)\n",
    "\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred = np.clip(y_pred, 0, 100)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    rmse = mean_squared_error(y, y_pred, squared=False)\n",
    "    rsq = r2_score(y, y_pred)\n",
    "    feats = X.columns.tolist()\n",
    "\n",
    "    return y_pred, mae, rmse, rsq, feats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create the lists to use with itertools.product\n",
    "model_types = [\"XGB\", \"RF\", \"ENET\", \"HGBM\", \"LGBM\"]\n",
    "region_names = [\"CARB\", \"SEAA\", \"GLOB\"]\n",
    "\n",
    "# Create a list to store the results of each run\n",
    "results_list = []\n",
    "\n",
    "# Loop over the combinations of model and region \n",
    "# for all standard model/region combinations\n",
    "for m,r in list(itertools.product(model_types, region_names)):\n",
    "    # XGB and LGBM have different feature lists\n",
    "    if m == \"XGB\" or m == \"LGBM\":\n",
    "        feat_list = globals()[f\"{r}_{m}_feat_list\"]\n",
    "    else:\n",
    "        feat_list = None\n",
    "\n",
    "    # Load the model from the global variable\n",
    "    model = globals()[f\"{r}_{m}_model\"]\n",
    "\n",
    "    # Loop over the validation and holdout sets\n",
    "    for d in ['v', 'h']:\n",
    "        X, y = globals()[f\"{r}_X{d}t\"], globals()[f\"{r}_y{d}\"]\n",
    "        y_pred, mae, rmse, rsq, feats = model_prediction(model, X, y, features=feat_list)\n",
    "        results_list.append([d, m, r, mae, rmse, rsq, feats])\n",
    "\n",
    "# Another for loop to add the dummy model\n",
    "for r in region_names:\n",
    "    # Loop over the validation and holdout sets\n",
    "    for d in ['v', 'h']:\n",
    "        y_pred, mae, rmse, rsq, feats = dummy_model_prediction(globals()[f\"{r}_X{d}t\"], globals()[f\"{r}_y{d}\"])\n",
    "        results_list.append([d, 'Dummy', r, mae, rmse, rsq, feats])\n",
    "\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "results = pd.DataFrame(results_list, columns=[\"split\",\"model\", \"region\", \"mae\", \"rmse\", \"rsq\", \"features\"])\n",
    "results['split'].replace({'t':'Training', 'v':'Validation', 'h':'Holdout'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "results[results['split']=='Holdout'][['model','region','mae','rmse','rsq']].round(4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "results[results['split'] == 'Holdout'].groupby(\n",
    "    'region', as_index=False\n",
    "    ).apply(\n",
    "        lambda x: x.loc[x['mae'].idxmin()]\n",
    "        )[['region','model','mae']].round(4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "results[results['split']=='Holdout'][['model','region','mae','rmse','rsq']].round(4)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "deepnote_persisted_session": {
   "createdAt": "2024-04-14T12:45:20.334Z"
  },
  "deepnote_notebook_id": "0e275273b8204d6e9709a99ea462f21c",
  "deepnote_execution_queue": [],
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 }
}
